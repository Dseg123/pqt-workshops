{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/de7281/pqt-workshops/.venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/adhoppin/financial-data?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.22M/4.22M [00:00<00:00, 73.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Path to dataset files: /home/de7281/.cache/kagglehub/datasets/adhoppin/financial-data/versions/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"adhoppin/financial-data\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Exercise 1: Parameter Optimization\n**Goal**: Find the optimal EWMA spans for better performance\n\n```python\n# Hint: Try different combinations of span_short and span_long\n# Compare Sharpe ratios across different parameter combinations\n```\n\n### Exercise 2: Train-Test Split\n**Goal**: Split data into training and testing periods to avoid overfitting\n\n```python\n# Hint: Use first 70% of data for training, last 30% for testing\n# Develop strategy parameters on training set only\n# Then test on out-of-sample test set\n```\n\n### Exercise 3: Different Stocks\n**Goal**: Test the same strategy on other stocks\n\n```python\n# Hint: Try stocks with different characteristics:\n# - High volatility (e.g., TSLA)\n# - Stable dividend payers (e.g., KO, JNJ)\n# - Tech stocks (e.g., GOOGL, MSFT)\n```\n\n### Exercise 4: Alternative Indicators\n**Goal**: Create signals using different technical indicators\n\n```python\n# Ideas:\n# - RSI (Relative Strength Index)\n# - Bollinger Bands (mean reversion)\n# - MACD (Moving Average Convergence Divergence)\n# - Volume-weighted indicators\n```\n\n### Exercise 5: Risk Management\n**Goal**: Add stop-loss and position sizing rules\n\n```python\n# Ideas:\n# - Implement a maximum drawdown threshold (exit if down X%)\n# - Use volatility-based position sizing\n# - Add maximum position limits\n# - Implement trailing stops\n```\n\n### Exercise 6: Multiple Timeframes\n**Goal**: Use signals from multiple timeframes (daily, weekly, monthly)\n\n```python\n# Hint: Resample data to different frequencies\n# Combine signals from different timeframes\n# Weight them appropriately\n```\n\n---\n\n## Additional Resources\n\n- **Books**:\n  - \"Quantitative Trading\" by Ernest Chan\n  - \"Algorithmic Trading\" by Stefan Jansen\n  - \"Advances in Financial Machine Learning\" by Marcos López de Prado\n\n- **Libraries to Explore**:\n  - `backtrader`: Full-featured backtesting framework\n  - `zipline`: Professional backtesting used by Quantopian\n  - `vectorbt`: Fast backtesting with vectorized operations\n  - `ta-lib`: Technical analysis library\n\n- **Next Topics**:\n  - Machine learning for trading\n  - Portfolio optimization\n  - Risk modeling (VaR, CVaR)\n  - Market microstructure\n  - High-frequency trading",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Summary and Key Takeaways\n\nCongratulations! You've built your first quantitative trading strategy. Here's what we covered:\n\n### 1. **Exploratory Data Analysis**\n   - Examined price trends and return distributions\n   - Calculated basic statistics (mean, volatility, skewness, kurtosis)\n   \n### 2. **Autocorrelation**\n   - Tested whether past returns predict future returns\n   - Learned that most autocorrelations are small but potentially exploitable\n   \n### 3. **EWMA Signals**\n   - Created momentum signals using exponentially weighted moving averages\n   - Visualized when to enter/exit positions\n   \n### 4. **Statistical Testing**\n   - Used t-statistics to test if signals are statistically significant\n   - Compared returns during long vs short signals\n   \n### 5. **Backtesting**\n   - Simulated historical performance\n   - Calculated key metrics: returns, Sharpe ratio, drawdown\n   - Compared to buy-and-hold benchmark\n   \n### 6. **Signal to Trades**\n   - Converted signals into actual positions\n   - Accounted for transaction costs\n   - Tracked portfolio value over time\n\n### Important Caveats:\n- **Overfitting**: We tested on the same data used to develop the strategy\n- **Transaction Costs**: Real costs may be higher and include market impact\n- **Market Conditions**: Past performance doesn't guarantee future results\n- **Risk Management**: We didn't implement position sizing or stop losses\n- **Data Issues**: Survivorship bias, look-ahead bias, etc.\n\n---\n\n## Exercises for Further Exploration\n\nTry these exercises to deepen your understanding:",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Simulate portfolio with transaction costs\ninitial_capital = 100000  # Start with $100,000\ntransaction_cost = 0.001  # 0.1% per trade (commissions + slippage)\n\n# Calculate portfolio value over time\ndf_aapl['portfolio_value'] = initial_capital\ndf_aapl['cash'] = initial_capital\ndf_aapl['holdings_value'] = 0.0\n\nportfolio_value = initial_capital\ncash = initial_capital\nshares = 0\n\nportfolio_values = []\ncash_values = []\nholdings_values = []\n\nfor idx in range(len(df_aapl)):\n    if idx == 0:\n        portfolio_values.append(initial_capital)\n        cash_values.append(cash)\n        holdings_values.append(0)\n        continue\n    \n    current_price = df_aapl.iloc[idx][price_col]\n    position = df_aapl.iloc[idx]['position']\n    prev_position = df_aapl.iloc[idx-1]['position']\n    \n    # Update holdings value based on price change\n    holdings_value = shares * current_price\n    \n    # Check if position changed (trade occurred)\n    if position != prev_position and not pd.isna(position) and not pd.isna(prev_position):\n        # Close old position\n        cash += shares * current_price * (1 - transaction_cost if shares > 0 else 1 + transaction_cost)\n        shares = 0\n        \n        # Open new position\n        if position != 0:\n            target_value = portfolio_value * abs(position)\n            shares_to_buy = target_value / current_price\n            cost = shares_to_buy * current_price * (1 + transaction_cost)\n            \n            if cost <= cash:\n                shares = shares_to_buy if position > 0 else -shares_to_buy\n                cash -= cost\n    \n    # Update portfolio value\n    holdings_value = shares * current_price\n    portfolio_value = cash + holdings_value\n    \n    portfolio_values.append(portfolio_value)\n    cash_values.append(cash)\n    holdings_values.append(holdings_value)\n\ndf_aapl['portfolio_value'] = portfolio_values\ndf_aapl['cash'] = cash_values\ndf_aapl['holdings_value'] = holdings_values\ndf_aapl['portfolio_returns'] = df_aapl['portfolio_value'].pct_change()\n\n# Plot portfolio value\nfig, axes = plt.subplots(2, 1, figsize=(14, 10))\n\n# Portfolio value over time\nax1 = axes[0]\nax1.plot(df_aapl[date_col], df_aapl['portfolio_value'], label='Portfolio Value', linewidth=2)\nax1.axhline(y=initial_capital, color='black', linestyle='--', alpha=0.5, label='Initial Capital')\nax1.set_title('Portfolio Value Over Time (with Transaction Costs)', fontsize=14, fontweight='bold')\nax1.set_ylabel('Portfolio Value ($)')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Cash vs Holdings\nax2 = axes[1]\nax2.fill_between(df_aapl[date_col], 0, df_aapl['cash'], alpha=0.5, label='Cash')\nax2.fill_between(df_aapl[date_col], df_aapl['cash'], df_aapl['portfolio_value'], alpha=0.5, label='Holdings')\nax2.set_title('Portfolio Composition', fontsize=14, fontweight='bold')\nax2.set_xlabel('Date')\nax2.set_ylabel('Value ($)')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Calculate final metrics\nfinal_value = df_aapl['portfolio_value'].iloc[-1]\ntotal_return = (final_value - initial_capital) / initial_capital\nprint(f\"\\nPortfolio Performance (with {transaction_cost*100}% transaction costs):\")\nprint(f\"  Initial Capital: ${initial_capital:,.2f}\")\nprint(f\"  Final Value: ${final_value:,.2f}\")\nprint(f\"  Total Return: {total_return*100:.2f}%\")\nprint(f\"  Number of Trades: {n_trades}\")\nprint(f\"  Transaction Costs: ${n_trades * initial_capital * transaction_cost:,.2f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Convert signals to positions\n# Position represents how much capital we allocate (as fraction of total portfolio)\n# Signal = 1 → Position = 1.0 (100% long)\n# Signal = -1 → Position = -1.0 (100% short)\n# Signal = 0 → Position = 0.0 (no position/cash)\n\ndf_aapl['position'] = df_aapl['signal_lagged']\n\n# Identify trades (when position changes)\ndf_aapl['position_change'] = df_aapl['position'].diff()\ndf_aapl['trade'] = (df_aapl['position_change'] != 0) & (df_aapl['position_change'].notna())\n\n# Count trades\ntrades_df = df_aapl[df_aapl['trade']].copy()\nn_trades = len(trades_df)\n\nprint(f\"Total number of trades: {n_trades}\")\nprint(f\"\\nFirst 10 trades:\")\nprint(trades_df[[date_col, price_col, 'position', 'position_change']].head(10))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 8: From Signals to Trades\n\nSo far we've been working with **signals** (-1, 0, 1). Now let's convert these into actual **trading positions** and track our portfolio.\n\n### Key Concepts:\n- **Position**: The number of shares we hold (or dollars invested)\n- **Position Changes**: When we enter/exit positions (these are actual trades)\n- **Transaction Costs**: In reality, every trade has costs (commissions, slippage)\n- **Portfolio Value**: Track how our total capital changes over time\n\nLet's build a simple position tracking system.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualize drawdowns\nfig, axes = plt.subplots(2, 1, figsize=(14, 10))\n\n# Calculate drawdowns\ndef calculate_drawdown(returns):\n    cumulative = (1 + returns).cumprod()\n    running_max = cumulative.expanding().max()\n    drawdown = (cumulative - running_max) / running_max\n    return drawdown\n\nstrategy_dd = calculate_drawdown(df_aapl['strategy_returns'].fillna(0))\nbuyhold_dd = calculate_drawdown(df_aapl['buy_hold_returns'].fillna(0))\n\n# Plot strategy drawdown\nax1 = axes[0]\nax1.fill_between(df_aapl[date_col], strategy_dd * 100, 0, alpha=0.5, color='red')\nax1.set_title('EWMA Strategy Drawdown', fontsize=14, fontweight='bold')\nax1.set_ylabel('Drawdown (%)')\nax1.grid(True, alpha=0.3)\n\n# Plot buy & hold drawdown\nax2 = axes[1]\nax2.fill_between(df_aapl[date_col], buyhold_dd * 100, 0, alpha=0.5, color='blue')\nax2.set_title('Buy & Hold Drawdown', fontsize=14, fontweight='bold')\nax2.set_xlabel('Date')\nax2.set_ylabel('Drawdown (%)')\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Calculate performance metrics\ndef calculate_metrics(returns, name=\"Strategy\"):\n    \"\"\"Calculate common performance metrics\"\"\"\n    returns_clean = returns.dropna()\n    \n    # Total return\n    total_return = (1 + returns_clean).prod() - 1\n    \n    # Annualized return (assuming 252 trading days)\n    n_days = len(returns_clean)\n    annualized_return = (1 + total_return) ** (252 / n_days) - 1\n    \n    # Volatility (annualized)\n    volatility = returns_clean.std() * np.sqrt(252)\n    \n    # Sharpe ratio (assuming 0% risk-free rate)\n    sharpe_ratio = annualized_return / volatility if volatility > 0 else 0\n    \n    # Maximum drawdown\n    cumulative = (1 + returns_clean).cumprod()\n    running_max = cumulative.expanding().max()\n    drawdown = (cumulative - running_max) / running_max\n    max_drawdown = drawdown.min()\n    \n    # Win rate\n    win_rate = (returns_clean > 0).sum() / len(returns_clean)\n    \n    # Average win/loss\n    wins = returns_clean[returns_clean > 0]\n    losses = returns_clean[returns_clean < 0]\n    avg_win = wins.mean() if len(wins) > 0 else 0\n    avg_loss = losses.mean() if len(losses) > 0 else 0\n    \n    print(f\"\\n{name}:\")\n    print(f\"  Total Return: {total_return*100:.2f}%\")\n    print(f\"  Annualized Return: {annualized_return*100:.2f}%\")\n    print(f\"  Annualized Volatility: {volatility*100:.2f}%\")\n    print(f\"  Sharpe Ratio: {sharpe_ratio:.4f}\")\n    print(f\"  Maximum Drawdown: {max_drawdown*100:.2f}%\")\n    print(f\"  Win Rate: {win_rate*100:.2f}%\")\n    print(f\"  Average Win: {avg_win*100:.4f}%\")\n    print(f\"  Average Loss: {avg_loss*100:.4f}%\")\n    print(f\"  Number of Trades: {len(returns_clean)}\")\n    \n    return {\n        'total_return': total_return,\n        'annualized_return': annualized_return,\n        'volatility': volatility,\n        'sharpe_ratio': sharpe_ratio,\n        'max_drawdown': max_drawdown,\n        'win_rate': win_rate\n    }\n\n# Calculate metrics for both strategies\nstrategy_metrics = calculate_metrics(df_aapl['strategy_returns'], \"EWMA Strategy\")\nbuyhold_metrics = calculate_metrics(df_aapl['buy_hold_returns'], \"Buy & Hold\")\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Calculate strategy returns\n# Strategy return = signal * forward return\n# We use the lagged signal to avoid look-ahead bias\ndf_aapl['strategy_returns'] = df_aapl['signal_lagged'] * df_aapl['returns']\n\n# Calculate cumulative returns\ndf_aapl['cumulative_returns'] = (1 + df_aapl['returns']).cumprod() - 1\ndf_aapl['cumulative_strategy_returns'] = (1 + df_aapl['strategy_returns']).cumprod() - 1\n\n# Buy and hold benchmark\ndf_aapl['buy_hold_returns'] = df_aapl['returns']\ndf_aapl['cumulative_buy_hold'] = (1 + df_aapl['buy_hold_returns']).cumprod() - 1\n\n# Plot cumulative returns\nfig, ax = plt.subplots(figsize=(14, 7))\n\nax.plot(df_aapl[date_col], df_aapl['cumulative_strategy_returns'] * 100, \n        label='EWMA Strategy', linewidth=2)\nax.plot(df_aapl[date_col], df_aapl['cumulative_buy_hold'] * 100, \n        label='Buy & Hold', linewidth=2, alpha=0.7)\n\nax.set_title('Strategy Performance vs Buy & Hold', fontsize=14, fontweight='bold')\nax.set_xlabel('Date')\nax.set_ylabel('Cumulative Returns (%)')\nax.legend(loc='best')\nax.grid(True, alpha=0.3)\nax.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Print summary statistics\nprint(\"=\" * 60)\nprint(\"BACKTEST PERFORMANCE SUMMARY\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 7: Backtesting the Strategy\n\nNow let's see how our strategy would have performed historically. **Backtesting** simulates trading based on historical data.\n\n### Key Metrics:\n- **Cumulative Returns**: Total return over the period\n- **Sharpe Ratio**: Risk-adjusted return (return per unit of volatility)\n- **Maximum Drawdown**: Largest peak-to-trough decline\n- **Win Rate**: Percentage of profitable trades\n\n### Important Note:\n⚠️ Backtesting on the same data used to develop the strategy can lead to **overfitting**. In practice, you should:\n1. Split data into training and testing sets\n2. Develop strategy on training set\n3. Test on out-of-sample data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Visualize returns distribution by signal\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Box plot\nax1 = axes[0]\ndata_to_plot = [returns_long, returns_short]\nlabels = ['Long (1)', 'Short (-1)']\nbp = ax1.boxplot(data_to_plot, labels=labels, patch_artist=True)\nbp['boxes'][0].set_facecolor('green')\nbp['boxes'][0].set_alpha(0.5)\nbp['boxes'][1].set_facecolor('red')\nbp['boxes'][1].set_alpha(0.5)\nax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)\nax1.set_title('Returns Distribution by Signal', fontsize=14, fontweight='bold')\nax1.set_ylabel('Returns')\nax1.grid(True, alpha=0.3)\n\n# Histogram comparison\nax2 = axes[1]\nax2.hist(returns_long, bins=30, alpha=0.5, label='Long', color='green', density=True)\nax2.hist(returns_short, bins=30, alpha=0.5, label='Short', color='red', density=True)\nax2.axvline(x=returns_long.mean(), color='green', linestyle='--', linewidth=2, label=f'Long mean: {returns_long.mean():.4f}')\nax2.axvline(x=returns_short.mean(), color='red', linestyle='--', linewidth=2, label=f'Short mean: {returns_short.mean():.4f}')\nax2.set_title('Returns Distribution Comparison', fontsize=14, fontweight='bold')\nax2.set_xlabel('Returns')\nax2.set_ylabel('Density')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Calculate forward returns (next period's return based on current signal)\n# Shift signal by 1 to avoid look-ahead bias\ndf_aapl['forward_returns'] = df_aapl['returns'].shift(-1)\ndf_aapl['signal_lagged'] = df_aapl['signal'].shift(1)\n\n# Remove NaN values\ndf_test = df_aapl[['signal_lagged', 'forward_returns']].dropna()\n\n# Split returns by signal\nreturns_long = df_test[df_test['signal_lagged'] == 1]['forward_returns']\nreturns_short = df_test[df_test['signal_lagged'] == -1]['forward_returns']\nreturns_neutral = df_test[df_test['signal_lagged'] == 0]['forward_returns']\n\nprint(\"=\" * 60)\nprint(\"STATISTICAL ANALYSIS OF SIGNALS\")\nprint(\"=\" * 60)\n\n# Long signal statistics\nif len(returns_long) > 0:\n    mean_long = returns_long.mean()\n    std_long = returns_long.std()\n    t_stat_long = mean_long / (std_long / np.sqrt(len(returns_long)))\n    p_value_long = stats.t.sf(abs(t_stat_long), len(returns_long) - 1) * 2\n    \n    print(f\"\\nLONG SIGNALS (signal = 1):\")\n    print(f\"  Number of observations: {len(returns_long)}\")\n    print(f\"  Mean return: {mean_long:.6f} ({mean_long*100:.4f}%)\")\n    print(f\"  Std dev: {std_long:.6f}\")\n    print(f\"  T-statistic: {t_stat_long:.4f}\")\n    print(f\"  P-value: {p_value_long:.4f}\")\n    print(f\"  Significant at 95%? {'YES' if abs(t_stat_long) > 1.96 else 'NO'}\")\n\n# Short signal statistics\nif len(returns_short) > 0:\n    mean_short = returns_short.mean()\n    std_short = returns_short.std()\n    t_stat_short = mean_short / (std_short / np.sqrt(len(returns_short)))\n    p_value_short = stats.t.sf(abs(t_stat_short), len(returns_short) - 1) * 2\n    \n    print(f\"\\nSHORT SIGNALS (signal = -1):\")\n    print(f\"  Number of observations: {len(returns_short)}\")\n    print(f\"  Mean return: {mean_short:.6f} ({mean_short*100:.4f}%)\")\n    print(f\"  Std dev: {std_short:.6f}\")\n    print(f\"  T-statistic: {t_stat_short:.4f}\")\n    print(f\"  P-value: {p_value_short:.4f}\")\n    print(f\"  Significant at 95%? {'YES' if abs(t_stat_short) > 1.96 else 'NO'}\")\n\n# Test difference between long and short\nif len(returns_long) > 0 and len(returns_short) > 0:\n    t_stat_diff, p_value_diff = stats.ttest_ind(returns_long, returns_short)\n    print(f\"\\nDIFFERENCE BETWEEN LONG AND SHORT:\")\n    print(f\"  Mean difference: {mean_long - mean_short:.6f}\")\n    print(f\"  T-statistic: {t_stat_diff:.4f}\")\n    print(f\"  P-value: {p_value_diff:.4f}\")\n    print(f\"  Significantly different? {'YES' if p_value_diff < 0.05 else 'NO'}\")\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 6: Statistical Testing with T-Statistics\n\nBefore we backtest our strategy, let's test whether our signals are statistically significant. We want to know:\n**\"Do returns when we have a buy signal differ significantly from returns when we have a sell signal?\"**\n\n### The T-Test:\nThe **t-statistic** measures how many standard errors a sample mean is from zero:\n\n$$t = \\frac{\\bar{x}}{\\text{SE}} = \\frac{\\bar{x}}{s / \\sqrt{n}}$$\n\nwhere:\n- $\\bar{x}$ is the sample mean\n- $s$ is the sample standard deviation\n- $n$ is the sample size\n- A **t-stat > 2** (approximately) is often considered statistically significant at the 95% confidence level",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Generate trading signal\n# Signal = 1 when fast EWMA > slow EWMA (bullish/buy)\n# Signal = -1 when fast EWMA < slow EWMA (bearish/sell)\n# Signal = 0 when no clear signal\n\ndf_aapl['signal'] = 0\ndf_aapl.loc[df_aapl['ewma_short'] > df_aapl['ewma_long'], 'signal'] = 1\ndf_aapl.loc[df_aapl['ewma_short'] < df_aapl['ewma_long'], 'signal'] = -1\n\n# Alternative: signal based on price vs single EWMA\ndf_aapl['signal_simple'] = 0\ndf_aapl.loc[df_aapl[price_col] > df_aapl['ewma_short'], 'signal_simple'] = 1\ndf_aapl.loc[df_aapl[price_col] < df_aapl['ewma_short'], 'signal_simple'] = -1\n\n# Visualize signals\nfig, axes = plt.subplots(2, 1, figsize=(14, 10))\n\n# Plot 1: Price with EWMA crossover signals\nax1 = axes[0]\nax1.plot(df_aapl[date_col], df_aapl[price_col], label='Price', alpha=0.6, linewidth=1)\nax1.plot(df_aapl[date_col], df_aapl['ewma_short'], label=f'EWMA {span_short}', alpha=0.7, linewidth=1.5)\nax1.plot(df_aapl[date_col], df_aapl['ewma_long'], label=f'EWMA {span_long}', alpha=0.7, linewidth=1.5)\n\n# Highlight buy/sell signals\nbuy_signals = df_aapl[df_aapl['signal'].diff() == 2]  # Changed from -1 to 1\nsell_signals = df_aapl[df_aapl['signal'].diff() == -2]  # Changed from 1 to -1\n\nax1.scatter(buy_signals[date_col], buy_signals[price_col], \n           color='green', marker='^', s=100, label='Buy Signal', zorder=5)\nax1.scatter(sell_signals[date_col], sell_signals[price_col], \n           color='red', marker='v', s=100, label='Sell Signal', zorder=5)\n\nax1.set_title('EWMA Crossover Strategy Signals', fontsize=14, fontweight='bold')\nax1.set_xlabel('Date')\nax1.set_ylabel('Price ($)')\nax1.legend(loc='best')\nax1.grid(True, alpha=0.3)\n\n# Plot 2: Signal over time\nax2 = axes[1]\nax2.fill_between(df_aapl[date_col], df_aapl['signal'], 0, \n                 where=(df_aapl['signal'] > 0), color='green', alpha=0.3, label='Long')\nax2.fill_between(df_aapl[date_col], df_aapl['signal'], 0, \n                 where=(df_aapl['signal'] < 0), color='red', alpha=0.3, label='Short')\nax2.set_title('Trading Signal Over Time', fontsize=14, fontweight='bold')\nax2.set_xlabel('Date')\nax2.set_ylabel('Signal')\nax2.set_ylim(-1.5, 1.5)\nax2.axhline(y=0, color='black', linestyle='-', alpha=0.5)\nax2.legend(loc='best')\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Print signal statistics\nprint(f\"Signal distribution:\")\nprint(df_aapl['signal'].value_counts())\nprint(f\"\\nPercentage of time long: {(df_aapl['signal'] == 1).sum() / len(df_aapl) * 100:.2f}%\")\nprint(f\"Percentage of time short: {(df_aapl['signal'] == -1).sum() / len(df_aapl) * 100:.2f}%\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Calculate EWMA with different spans\nspan_short = 10  # Fast EWMA (more reactive)\nspan_long = 50   # Slow EWMA (smoother)\n\ndf_aapl['ewma_short'] = df_aapl[price_col].ewm(span=span_short, adjust=False).mean()\ndf_aapl['ewma_long'] = df_aapl[price_col].ewm(span=span_long, adjust=False).mean()\n\n# Visualize EWMA\nfig, ax = plt.subplots(figsize=(14, 7))\n\nax.plot(df_aapl[date_col], df_aapl[price_col], label='Actual Price', alpha=0.7, linewidth=1.5)\nax.plot(df_aapl[date_col], df_aapl['ewma_short'], label=f'EWMA (span={span_short})', alpha=0.8, linewidth=1.5)\nax.plot(df_aapl[date_col], df_aapl['ewma_long'], label=f'EWMA (span={span_long})', alpha=0.8, linewidth=1.5)\n\nax.set_title('AAPL Price with EWMA Indicators', fontsize=14, fontweight='bold')\nax.set_xlabel('Date')\nax.set_ylabel('Price ($)')\nax.legend(loc='best')\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 5: Creating a Trading Signal with EWMA\n\n**Exponentially Weighted Moving Average (EWMA)** gives more weight to recent observations. Unlike a simple moving average, EWMA reacts faster to recent price changes.\n\n### The EWMA Formula:\n$$EWMA_t = \\alpha \\cdot X_t + (1-\\alpha) \\cdot EWMA_{t-1}$$\n\nwhere:\n- $\\alpha$ is the smoothing factor (0 < α < 1)\n- Higher α means more weight on recent values\n- Common alternative parameterization: $\\alpha = 2/(span + 1)$\n\n### Our Strategy:\nWe'll create a **momentum signal** based on EWMA:\n- If price > EWMA → **Buy signal** (upward momentum)\n- If price < EWMA → **Sell signal** (downward momentum)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Interpreting Autocorrelation:\n\n- Values **outside the confidence bands** (red dashed lines) are statistically significant\n- Most financial return series show **very low autocorrelation** (close to zero)\n- Even small autocorrelations can potentially be exploited for profit (though transaction costs matter!)\n- This supports the idea that markets are relatively **efficient** but not perfectly so",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Calculate autocorrelation for different lags\nfrom pandas.plotting import autocorrelation_plot\n\n# Remove NaN values\nreturns_clean = df_aapl['returns'].dropna()\n\n# Plot autocorrelation\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Autocorrelation plot\nax1 = axes[0]\nautocorrelation_plot(returns_clean, ax=ax1)\nax1.set_title('Autocorrelation of AAPL Returns', fontsize=14, fontweight='bold')\nax1.set_xlabel('Lag')\nax1.set_ylabel('Autocorrelation')\nax1.set_xlim(0, 50)\nax1.grid(True, alpha=0.3)\n\n# Manual autocorrelation for specific lags\nax2 = axes[1]\nlags = range(1, 21)\nautocorr_values = [returns_clean.autocorr(lag=i) for i in lags]\nax2.bar(lags, autocorr_values, alpha=0.7)\nax2.axhline(y=0, color='r', linestyle='-', alpha=0.5)\n# Add confidence intervals (95% confidence: ±1.96/sqrt(n))\nconf_interval = 1.96 / np.sqrt(len(returns_clean))\nax2.axhline(y=conf_interval, color='r', linestyle='--', alpha=0.5, label='95% confidence')\nax2.axhline(y=-conf_interval, color='r', linestyle='--', alpha=0.5)\nax2.set_title('Autocorrelation at Different Lags', fontsize=14, fontweight='bold')\nax2.set_xlabel('Lag (days)')\nax2.set_ylabel('Autocorrelation')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Print specific lag autocorrelations\nprint(\"Autocorrelation values:\")\nfor lag in [1, 2, 3, 5, 10]:\n    acf = returns_clean.autocorr(lag=lag)\n    print(f\"  Lag {lag}: {acf:.6f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 4: Autocorrelation Analysis\n\n**Autocorrelation** measures how much a time series is correlated with itself at different time lags. In the context of stock returns:\n- **Positive autocorrelation** at lag 1 means that positive returns tend to be followed by positive returns (momentum)\n- **Negative autocorrelation** means positive returns tend to be followed by negative returns (mean reversion)\n- **Zero autocorrelation** suggests returns are independent (random walk hypothesis)\n\nLet's investigate whether AAPL returns exhibit autocorrelation.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "### Key Observations from EDA:\n\n1. **Price Trend**: We can see the overall price trajectory of AAPL\n2. **Returns Distribution**: Daily returns appear to be roughly normally distributed (though often with fat tails)\n3. **Volatility**: The standard deviation of returns gives us a measure of volatility\n4. **Skewness & Kurtosis**: Tell us about asymmetry and tail thickness in the distribution\n\n**Question to think about**: Do you notice any patterns or trends that might be exploitable for prediction?",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Calculate returns\n# Returns are the percentage change in price from one period to the next\ndf_aapl['returns'] = df_aapl[price_col].pct_change()\n\n# Visualize returns distribution\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Returns over time\nax1 = axes[0]\nax1.plot(df_aapl[date_col], df_aapl['returns'], linewidth=0.8, alpha=0.7)\nax1.axhline(y=0, color='r', linestyle='--', alpha=0.5)\nax1.set_title('AAPL Daily Returns Over Time', fontsize=14, fontweight='bold')\nax1.set_xlabel('Date')\nax1.set_ylabel('Returns')\nax1.grid(True, alpha=0.3)\n\n# Returns distribution\nax2 = axes[1]\nax2.hist(df_aapl['returns'].dropna(), bins=50, edgecolor='black', alpha=0.7)\nax2.set_title('Distribution of Daily Returns', fontsize=14, fontweight='bold')\nax2.set_xlabel('Returns')\nax2.set_ylabel('Frequency')\nax2.axvline(x=0, color='r', linestyle='--', alpha=0.5)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Print return statistics\nprint(f\"Mean daily return: {df_aapl['returns'].mean():.6f}\")\nprint(f\"Std dev of returns: {df_aapl['returns'].std():.6f}\")\nprint(f\"Skewness: {df_aapl['returns'].skew():.4f}\")\nprint(f\"Kurtosis: {df_aapl['returns'].kurtosis():.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Visualize price over time\nfig, axes = plt.subplots(2, 1, figsize=(14, 8))\n\n# Price chart\nax1 = axes[0]\nprice_col = 'Close' if 'Close' in df_aapl.columns else 'close' if 'close' in df_aapl.columns else df_aapl.select_dtypes(include=[np.number]).columns[0]\nax1.plot(df_aapl[date_col], df_aapl[price_col], linewidth=1.5)\nax1.set_title('AAPL Closing Price Over Time', fontsize=14, fontweight='bold')\nax1.set_xlabel('Date')\nax1.set_ylabel('Price ($)')\nax1.grid(True, alpha=0.3)\n\n# Volume chart (if available)\nax2 = axes[1]\nvolume_col = 'Volume' if 'Volume' in df_aapl.columns else 'volume' if 'volume' in df_aapl.columns else None\nif volume_col:\n    ax2.bar(df_aapl[date_col], df_aapl[volume_col], alpha=0.7, width=1.0)\n    ax2.set_title('AAPL Trading Volume Over Time', fontsize=14, fontweight='bold')\n    ax2.set_xlabel('Date')\n    ax2.set_ylabel('Volume')\n    ax2.grid(True, alpha=0.3)\nelse:\n    ax2.text(0.5, 0.5, 'Volume data not available', ha='center', va='center', fontsize=12)\n    ax2.set_xticks([])\n    ax2.set_yticks([])\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Basic statistics\nprint(\"Summary Statistics:\")\nprint(df_aapl.describe())\n\n# Check for missing values\nprint(f\"\\nMissing values in AAPL data:\")\nprint(df_aapl.isnull().sum())",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 3: Exploratory Data Analysis (EDA)\n\nLet's explore the AAPL stock data to understand its characteristics, trends, and patterns.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Filter for AAPL\n# Adapt this based on the actual column name in the dataset\nticker_col = 'Symbol' if 'Symbol' in df_raw.columns else 'Ticker' if 'Ticker' in df_raw.columns else df_raw.columns[0]\ndate_col = 'Date' if 'Date' in df_raw.columns else df_raw.columns[0]\n\ndf_aapl = df_raw[df_raw[ticker_col] == 'AAPL'].copy()\n\n# Convert date column to datetime\ndf_aapl[date_col] = pd.to_datetime(df_aapl[date_col])\ndf_aapl = df_aapl.sort_values(date_col).reset_index(drop=True)\n\nprint(f\"AAPL data shape: {df_aapl.shape}\")\nprint(f\"Date range: {df_aapl[date_col].min()} to {df_aapl[date_col].max()}\")\nprint(f\"\\nFirst few rows:\")\ndf_aapl.head(10)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 2: Extract AAPL Data\n\nNow let's filter the dataset to focus on Apple (AAPL) stock and prepare it for analysis.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Explore the dataset structure\nprint(\"Column names:\")\nprint(df_raw.columns.tolist())\nprint(f\"\\nData types:\")\nprint(df_raw.dtypes)\nprint(f\"\\nMissing values:\")\nprint(df_raw.isnull().sum())\n\n# Check unique tickers if available\nif 'Symbol' in df_raw.columns or 'Ticker' in df_raw.columns:\n    ticker_col = 'Symbol' if 'Symbol' in df_raw.columns else 'Ticker'\n    print(f\"\\nUnique tickers: {df_raw[ticker_col].nunique()}\")\n    print(f\"Tickers include: {df_raw[ticker_col].unique()[:10]}\")  # Show first 10",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# List files in the dataset directory\ndataset_files = os.listdir(path)\nprint(\"Files in dataset:\")\nfor file in dataset_files:\n    print(f\"  - {file}\")\n    \n# Load the main CSV file\ndata_file = [f for f in dataset_files if f.endswith('.csv')][0]\ndf_raw = pd.read_csv(os.path.join(path, data_file))\n\nprint(f\"\\nLoaded {data_file}\")\nprint(f\"Shape: {df_raw.shape}\")\nprint(f\"\\nFirst few rows:\")\ndf_raw.head()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Step 1: Load and Explore the Dataset\n\nLet's start by loading the financial data from Kaggle and exploring what's available.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport os\n\n# Set style for better-looking plots\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n%matplotlib inline\n\n# Display settings\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 4)\n\nprint(\"Libraries imported successfully!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Workshop 1: Introduction to Quantitative Trading\n## Predicting Stock Prices with Simple Statistical Methods\n\nWelcome to this introductory workshop on quantitative finance! In this workshop, we'll explore:\n\n1. **Exploratory Data Analysis (EDA)** - Understanding our stock price data\n2. **Autocorrelation** - How past prices relate to future prices\n3. **Exponentially Weighted Moving Averages (EWMA)** - Creating trading signals\n4. **Statistical Testing** - Validating our signals with t-statistics\n5. **Backtesting** - Testing our strategy on historical data\n6. **Signal to Trades** - Converting predictions into actual trading decisions\n\nWe'll focus on a single stock (AAPL) and try to predict the next timestep's price movement using only historical price data.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}